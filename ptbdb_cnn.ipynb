{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **First Attempt CNN - PTBDB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages and Data\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "ptbdb_abnormal_df = pd.read_csv(\"ptbdb_abnormal.csv\")\n",
    "ptbdb_normal_df = pd.read_csv(\"ptbdb_normal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188\n",
       "1    10505\n",
       "0     4045\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming the Columns\n",
    "new_column_names = range(1, len(ptbdb_normal_df.columns) + 1)\n",
    "ptbdb_normal_df.columns = new_column_names\n",
    "\n",
    "new_column_names = range(1, len(ptbdb_abnormal_df.columns) + 1)\n",
    "ptbdb_abnormal_df.columns = new_column_names\n",
    "\n",
    "# Combining the two Dataframes \n",
    "ptbdb_comb_df = pd.concat([ptbdb_normal_df, ptbdb_abnormal_df], ignore_index=True)\n",
    "\n",
    "# Transforming the Target Variable to Integer\n",
    "ptbdb_comb_df[188] = ptbdb_comb_df[188].astype(int)\n",
    "\n",
    "# Shuffle the rows of the DataFrame\n",
    "ptbdb_comb_df = ptbdb_comb_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "ptbdb_comb_df[188].value_counts()\n",
    "#ptbdb_comb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.598220</td>\n",
       "      <td>0.166324</td>\n",
       "      <td>0.010951</td>\n",
       "      <td>0.094456</td>\n",
       "      <td>0.492129</td>\n",
       "      <td>0.586585</td>\n",
       "      <td>0.587269</td>\n",
       "      <td>0.620808</td>\n",
       "      <td>0.637235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.953488</td>\n",
       "      <td>0.725914</td>\n",
       "      <td>0.291251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060354</td>\n",
       "      <td>0.126246</td>\n",
       "      <td>0.156146</td>\n",
       "      <td>0.166113</td>\n",
       "      <td>0.168882</td>\n",
       "      <td>0.182724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.969398</td>\n",
       "      <td>0.408687</td>\n",
       "      <td>0.107601</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.072063</td>\n",
       "      <td>0.136723</td>\n",
       "      <td>0.106614</td>\n",
       "      <td>0.096742</td>\n",
       "      <td>0.144126</td>\n",
       "      <td>0.090326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585916</td>\n",
       "      <td>0.114366</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092958</td>\n",
       "      <td>0.235493</td>\n",
       "      <td>0.283944</td>\n",
       "      <td>0.294085</td>\n",
       "      <td>0.329014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.959442</td>\n",
       "      <td>0.884867</td>\n",
       "      <td>0.438290</td>\n",
       "      <td>0.104666</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.016136</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.011339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.966691</td>\n",
       "      <td>0.751629</td>\n",
       "      <td>0.436640</td>\n",
       "      <td>0.328023</td>\n",
       "      <td>0.217234</td>\n",
       "      <td>0.118030</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.070963</td>\n",
       "      <td>0.075308</td>\n",
       "      <td>0.049964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.766389</td>\n",
       "      <td>0.363528</td>\n",
       "      <td>0.296782</td>\n",
       "      <td>0.107271</td>\n",
       "      <td>0.063170</td>\n",
       "      <td>0.025030</td>\n",
       "      <td>0.005959</td>\n",
       "      <td>0.060787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.815076</td>\n",
       "      <td>0.391335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108137</td>\n",
       "      <td>0.181402</td>\n",
       "      <td>0.237760</td>\n",
       "      <td>0.379007</td>\n",
       "      <td>0.453681</td>\n",
       "      <td>0.477985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.415168</td>\n",
       "      <td>0.031599</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.028683</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>0.133690</td>\n",
       "      <td>0.139524</td>\n",
       "      <td>0.144871</td>\n",
       "      <td>0.155080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.866707</td>\n",
       "      <td>0.880579</td>\n",
       "      <td>0.874548</td>\n",
       "      <td>0.835344</td>\n",
       "      <td>0.802774</td>\n",
       "      <td>0.770205</td>\n",
       "      <td>0.754524</td>\n",
       "      <td>0.749095</td>\n",
       "      <td>0.729192</td>\n",
       "      <td>0.700844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1         2         3         4         5         6         7    \\\n",
       "0  1.000000  0.598220  0.166324  0.010951  0.094456  0.492129  0.586585   \n",
       "1  0.953488  0.725914  0.291251  0.000000  0.060354  0.126246  0.156146   \n",
       "2  0.969398  0.408687  0.107601  0.038500  0.072063  0.136723  0.106614   \n",
       "3  1.000000  0.585916  0.114366  0.006197  0.000000  0.092958  0.235493   \n",
       "4  0.959442  0.884867  0.438290  0.104666  0.003925  0.000000  0.013956   \n",
       "5  0.966691  0.751629  0.436640  0.328023  0.217234  0.118030  0.102100   \n",
       "6  1.000000  0.766389  0.363528  0.296782  0.107271  0.063170  0.025030   \n",
       "7  1.000000  0.815076  0.391335  0.000000  0.108137  0.181402  0.237760   \n",
       "8  1.000000  0.415168  0.031599  0.001945  0.028683  0.082645  0.133690   \n",
       "9  0.866707  0.880579  0.874548  0.835344  0.802774  0.770205  0.754524   \n",
       "\n",
       "        8         9         10   ...  179  180  181  182  183  184  185  186  \\\n",
       "0  0.587269  0.620808  0.637235  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.166113  0.168882  0.182724  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2  0.096742  0.144126  0.090326  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.283944  0.294085  0.329014  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.016136  0.001744  0.011339  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "5  0.070963  0.075308  0.049964  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "6  0.005959  0.060787  0.000000  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "7  0.379007  0.453681  0.477985  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "8  0.139524  0.144871  0.155080  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "9  0.749095  0.729192  0.700844  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   187  188  \n",
       "0  0.0    1  \n",
       "1  0.0    1  \n",
       "2  0.0    1  \n",
       "3  0.0    1  \n",
       "4  0.0    0  \n",
       "5  0.0    1  \n",
       "6  0.0    1  \n",
       "7  0.0    1  \n",
       "8  0.0    0  \n",
       "9  0.0    0  \n",
       "\n",
       "[10 rows x 188 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=1, stop=189, step=1)\n",
      "RangeIndex(start=1, stop=189, step=1)\n",
      "(4045, 188)\n",
      "(10505, 188)\n"
     ]
    }
   ],
   "source": [
    "display(ptbdb_comb_df.head(10))\n",
    "print(ptbdb_normal_df.columns)\n",
    "print(ptbdb_abnormal_df.columns)\n",
    "print(ptbdb_normal_df.shape)\n",
    "print(ptbdb_abnormal_df.shape)\n",
    "\n",
    "# Abnormal == 1; Normal == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ML-Packages\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,  ClusterCentroids\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train_Test_Split: \n",
    "\n",
    "feats = ptbdb_comb_df.drop(188, axis = 1)\n",
    "target = ptbdb_comb_df[188]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size= 0.2, random_state = 42, stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model, Hyperparameter Optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7395 - loss: 0.5679 - val_accuracy: 0.7895 - val_loss: 0.4482\n",
      "Epoch 2/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7924 - loss: 0.4380 - val_accuracy: 0.8149 - val_loss: 0.3956\n",
      "Epoch 3/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8177 - loss: 0.3985 - val_accuracy: 0.8217 - val_loss: 0.3706\n",
      "Epoch 4/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8339 - loss: 0.3598 - val_accuracy: 0.7985 - val_loss: 0.3708\n",
      "Epoch 5/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8516 - loss: 0.3271 - val_accuracy: 0.8793 - val_loss: 0.2890\n",
      "Epoch 6/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8741 - loss: 0.2882 - val_accuracy: 0.8814 - val_loss: 0.2620\n",
      "Epoch 7/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8908 - loss: 0.2625 - val_accuracy: 0.9068 - val_loss: 0.2336\n",
      "Epoch 8/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9003 - loss: 0.2374 - val_accuracy: 0.9115 - val_loss: 0.2309\n",
      "Epoch 9/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9142 - loss: 0.2256 - val_accuracy: 0.9210 - val_loss: 0.2046\n",
      "Epoch 10/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9219 - loss: 0.2077 - val_accuracy: 0.9343 - val_loss: 0.1699\n",
      "Epoch 11/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9337 - loss: 0.1813 - val_accuracy: 0.9308 - val_loss: 0.1691\n",
      "Epoch 12/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9343 - loss: 0.1671 - val_accuracy: 0.9287 - val_loss: 0.1737\n",
      "Epoch 13/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9394 - loss: 0.1578 - val_accuracy: 0.9575 - val_loss: 0.1234\n",
      "Epoch 14/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9495 - loss: 0.1324 - val_accuracy: 0.9497 - val_loss: 0.1322\n",
      "Epoch 15/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9581 - loss: 0.1243 - val_accuracy: 0.9618 - val_loss: 0.1153\n",
      "Epoch 16/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9528 - loss: 0.1276 - val_accuracy: 0.9605 - val_loss: 0.1130\n",
      "Epoch 17/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9569 - loss: 0.1148 - val_accuracy: 0.9553 - val_loss: 0.1230\n",
      "Epoch 18/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9637 - loss: 0.1005 - val_accuracy: 0.9631 - val_loss: 0.0981\n",
      "Epoch 19/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9657 - loss: 0.0969 - val_accuracy: 0.9652 - val_loss: 0.0996\n",
      "Epoch 20/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9656 - loss: 0.0989 - val_accuracy: 0.9596 - val_loss: 0.1223\n",
      "Epoch 21/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9641 - loss: 0.0938 - val_accuracy: 0.9678 - val_loss: 0.0911\n",
      "Epoch 22/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9683 - loss: 0.0892 - val_accuracy: 0.9661 - val_loss: 0.1049\n",
      "Epoch 23/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9730 - loss: 0.0778 - val_accuracy: 0.9678 - val_loss: 0.0908\n",
      "Epoch 24/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9770 - loss: 0.0673 - val_accuracy: 0.9729 - val_loss: 0.0832\n",
      "Epoch 25/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9833 - loss: 0.0532 - val_accuracy: 0.9691 - val_loss: 0.0846\n",
      "Epoch 26/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9738 - loss: 0.0667 - val_accuracy: 0.9601 - val_loss: 0.1020\n",
      "Epoch 27/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9789 - loss: 0.0596 - val_accuracy: 0.9622 - val_loss: 0.0997\n",
      "Epoch 28/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9777 - loss: 0.0666 - val_accuracy: 0.9540 - val_loss: 0.1177\n",
      "Epoch 29/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9788 - loss: 0.0656 - val_accuracy: 0.9828 - val_loss: 0.0615\n",
      "Epoch 30/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9770 - loss: 0.0638 - val_accuracy: 0.9811 - val_loss: 0.0572\n",
      "Epoch 31/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9826 - loss: 0.0542 - val_accuracy: 0.9794 - val_loss: 0.0579\n",
      "Epoch 32/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9887 - loss: 0.0389 - val_accuracy: 0.9815 - val_loss: 0.0608\n",
      "Epoch 33/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9860 - loss: 0.0388 - val_accuracy: 0.9747 - val_loss: 0.0774\n",
      "Epoch 34/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9859 - loss: 0.0450 - val_accuracy: 0.9824 - val_loss: 0.0473\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Modell Input\n",
    "inputs = Input(shape=(187, 1), name=\"Input\")\n",
    "\n",
    "# 1D-CNN Layer\n",
    "first_layer = Conv1D(filters=64, kernel_size=3, activation='relu')\n",
    "second_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# Zweite CNN-Schicht hinzufügen\n",
    "third_layer = Conv1D(filters=128, kernel_size=3, activation='relu')\n",
    "fourth_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(100, return_sequences=False)\n",
    "\n",
    "# Dense Layers\n",
    "dense_layer = Dense(50, activation='relu')\n",
    "dropout_layer = Dropout(0.5)\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Verbindung der Layers\n",
    "x = first_layer(inputs)\n",
    "x = second_layer(x)\n",
    "x = third_layer(x)\n",
    "x = fourth_layer(x)\n",
    "x = lstm_layer(x)\n",
    "x = dense_layer(x)\n",
    "x = dropout_layer(x)\n",
    "outputs = output_layer(x)\n",
    "\n",
    "# Modell erstellen\n",
    "model1 = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Modell kompilieren\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "training_history = model1.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_acc = training_history.history['accuracy']\n",
    "val_acc = training_history.history['val_accuracy']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.plot(np.arange(1 ,35, 1),\n",
    "         training_history.history['accuracy'],\n",
    "         label = 'Training Accuracy',\n",
    "         color = 'blue')\n",
    "\n",
    "plt.plot(np.arange(1 , 35, 1),\n",
    "         training_history.history['val_accuracy'], \n",
    "         label = 'Validation Accuracy',\n",
    "         color = 'red')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       827\n",
      "           1       0.98      0.98      0.98      2083\n",
      "\n",
      "    accuracy                           0.98      2910\n",
      "   macro avg       0.97      0.97      0.97      2910\n",
      "weighted avg       0.98      0.98      0.98      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "# Da die Ausgabe des Modells Wahrscheinlichkeiten zwischen 0 und 1 ist, müssen wir diese in 0 oder 1 umwandeln\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.7218 - loss: 0.5851 - val_accuracy: 0.7367 - val_loss: 0.5037\n",
      "Epoch 2/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7530 - loss: 0.4837 - val_accuracy: 0.8011 - val_loss: 0.3926\n",
      "Epoch 3/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8275 - loss: 0.3729 - val_accuracy: 0.8600 - val_loss: 0.3260\n",
      "Epoch 4/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8946 - loss: 0.2786 - val_accuracy: 0.9094 - val_loss: 0.2578\n",
      "Epoch 5/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9161 - loss: 0.2395 - val_accuracy: 0.9296 - val_loss: 0.1955\n",
      "Epoch 6/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.9246 - loss: 0.2120 - val_accuracy: 0.9394 - val_loss: 0.1667\n",
      "Epoch 7/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9296 - loss: 0.1860 - val_accuracy: 0.9373 - val_loss: 0.1603\n",
      "Epoch 8/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.9328 - loss: 0.1755 - val_accuracy: 0.9446 - val_loss: 0.1433\n",
      "Epoch 9/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9447 - loss: 0.1536 - val_accuracy: 0.9407 - val_loss: 0.1493\n",
      "Epoch 10/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9468 - loss: 0.1400 - val_accuracy: 0.9433 - val_loss: 0.1415\n",
      "Epoch 11/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9531 - loss: 0.1260 - val_accuracy: 0.9682 - val_loss: 0.0921\n",
      "Epoch 12/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9612 - loss: 0.1121 - val_accuracy: 0.9570 - val_loss: 0.1077\n",
      "Epoch 13/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9611 - loss: 0.1038 - val_accuracy: 0.9575 - val_loss: 0.1182\n",
      "Epoch 14/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9696 - loss: 0.0899 - val_accuracy: 0.9734 - val_loss: 0.0715\n",
      "Epoch 15/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9743 - loss: 0.0767 - val_accuracy: 0.9747 - val_loss: 0.0750\n",
      "Epoch 16/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9768 - loss: 0.0712 - val_accuracy: 0.9764 - val_loss: 0.0734\n",
      "Epoch 17/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9775 - loss: 0.0609 - val_accuracy: 0.9764 - val_loss: 0.0678\n",
      "Epoch 18/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9803 - loss: 0.0634 - val_accuracy: 0.9493 - val_loss: 0.1272\n",
      "Epoch 19/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9779 - loss: 0.0630 - val_accuracy: 0.9661 - val_loss: 0.1094\n",
      "Epoch 20/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9775 - loss: 0.0674 - val_accuracy: 0.9764 - val_loss: 0.0871\n",
      "Epoch 21/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9770 - loss: 0.0593 - val_accuracy: 0.9832 - val_loss: 0.0457\n",
      "Epoch 22/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9813 - loss: 0.0541 - val_accuracy: 0.9725 - val_loss: 0.0679\n",
      "Epoch 23/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9815 - loss: 0.0572 - val_accuracy: 0.9854 - val_loss: 0.0460\n",
      "Epoch 24/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9853 - loss: 0.0429 - val_accuracy: 0.9708 - val_loss: 0.0766\n",
      "Epoch 25/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9884 - loss: 0.0365 - val_accuracy: 0.9712 - val_loss: 0.0804\n",
      "Epoch 26/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9876 - loss: 0.0410 - val_accuracy: 0.9781 - val_loss: 0.0643\n",
      "Epoch 27/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.9932 - loss: 0.0247 - val_accuracy: 0.9858 - val_loss: 0.0424\n",
      "Epoch 28/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9872 - loss: 0.0377 - val_accuracy: 0.9867 - val_loss: 0.0438\n",
      "Epoch 29/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9888 - loss: 0.0321 - val_accuracy: 0.9790 - val_loss: 0.0640\n",
      "Epoch 30/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9890 - loss: 0.0292 - val_accuracy: 0.9618 - val_loss: 0.1031\n",
      "Epoch 31/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9927 - loss: 0.0255 - val_accuracy: 0.9867 - val_loss: 0.0388\n",
      "Epoch 32/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9939 - loss: 0.0202 - val_accuracy: 0.9759 - val_loss: 0.0563\n",
      "Epoch 33/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9827 - loss: 0.0512 - val_accuracy: 0.9794 - val_loss: 0.0537\n"
     ]
    }
   ],
   "source": [
    "# Alterating Kernel Size: \n",
    "\n",
    "\n",
    "# Modell Input\n",
    "inputs = Input(shape=(187, 1), name=\"Input\")\n",
    "\n",
    "# 1D-CNN Layer\n",
    "first_layer = Conv1D(filters=64, kernel_size=5, activation='relu')   ####\n",
    "second_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# Zweite CNN-Schicht hinzufügen\n",
    "third_layer = Conv1D(filters=128, kernel_size=7, activation='relu')    ####\n",
    "fourth_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(100, return_sequences=False)\n",
    "\n",
    "# Dense Layers\n",
    "dense_layer = Dense(50, activation='relu')\n",
    "dropout_layer = Dropout(0.5)\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Verbindung der Layers\n",
    "x = first_layer(inputs)\n",
    "x = second_layer(x)\n",
    "x = third_layer(x)\n",
    "x = fourth_layer(x)\n",
    "x = lstm_layer(x)\n",
    "x = dense_layer(x)\n",
    "x = dropout_layer(x)\n",
    "outputs = output_layer(x)\n",
    "\n",
    "# Modell erstellen\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "training_history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       827\n",
      "           1       0.99      0.99      0.99      2083\n",
      "\n",
      "    accuracy                           0.98      2910\n",
      "   macro avg       0.98      0.98      0.98      2910\n",
      "weighted avg       0.98      0.98      0.98      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Da die Ausgabe des Modells Wahrscheinlichkeiten zwischen 0 und 1 ist, müssen wir diese in 0 oder 1 umwandeln\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Greatly improved performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7343 - loss: 0.5633 - val_accuracy: 0.7814 - val_loss: 0.4982\n",
      "Epoch 2/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7910 - loss: 0.4348 - val_accuracy: 0.8638 - val_loss: 0.3411\n",
      "Epoch 3/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8561 - loss: 0.3510 - val_accuracy: 0.9102 - val_loss: 0.2508\n",
      "Epoch 4/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8974 - loss: 0.2724 - val_accuracy: 0.8200 - val_loss: 0.4087\n",
      "Epoch 5/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9088 - loss: 0.2429 - val_accuracy: 0.8939 - val_loss: 0.2572\n",
      "Epoch 6/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9260 - loss: 0.2003 - val_accuracy: 0.9412 - val_loss: 0.1659\n",
      "Epoch 7/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9334 - loss: 0.1800 - val_accuracy: 0.9420 - val_loss: 0.1515\n",
      "Epoch 8/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9366 - loss: 0.1735 - val_accuracy: 0.9369 - val_loss: 0.1606\n",
      "Epoch 9/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9532 - loss: 0.1331 - val_accuracy: 0.9510 - val_loss: 0.1396\n",
      "Epoch 10/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9497 - loss: 0.1346 - val_accuracy: 0.9240 - val_loss: 0.1881\n",
      "Epoch 11/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9563 - loss: 0.1239 - val_accuracy: 0.9527 - val_loss: 0.1402\n",
      "Epoch 12/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9592 - loss: 0.1182 - val_accuracy: 0.9549 - val_loss: 0.1275\n",
      "Epoch 13/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9657 - loss: 0.0965 - val_accuracy: 0.9575 - val_loss: 0.1154\n",
      "Epoch 14/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9701 - loss: 0.0952 - val_accuracy: 0.9618 - val_loss: 0.1022\n",
      "Epoch 15/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9679 - loss: 0.0966 - val_accuracy: 0.9686 - val_loss: 0.0985\n",
      "Epoch 16/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9661 - loss: 0.0985 - val_accuracy: 0.9725 - val_loss: 0.0813\n",
      "Epoch 17/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9764 - loss: 0.0714 - val_accuracy: 0.9747 - val_loss: 0.0686\n",
      "Epoch 18/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9800 - loss: 0.0694 - val_accuracy: 0.9790 - val_loss: 0.0565\n",
      "Epoch 19/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9704 - loss: 0.0812 - val_accuracy: 0.9678 - val_loss: 0.0951\n",
      "Epoch 20/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9769 - loss: 0.0708 - val_accuracy: 0.9695 - val_loss: 0.0872\n",
      "Epoch 21/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9786 - loss: 0.0616 - val_accuracy: 0.9820 - val_loss: 0.0597\n",
      "Epoch 22/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9744 - loss: 0.0753 - val_accuracy: 0.9678 - val_loss: 0.0848\n",
      "Epoch 23/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9805 - loss: 0.0570 - val_accuracy: 0.9721 - val_loss: 0.0773\n",
      "Epoch 24/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9798 - loss: 0.0536 - val_accuracy: 0.9807 - val_loss: 0.0580\n",
      "Epoch 25/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9808 - loss: 0.0624 - val_accuracy: 0.9785 - val_loss: 0.0597\n",
      "Epoch 26/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9852 - loss: 0.0485 - val_accuracy: 0.9854 - val_loss: 0.0454\n",
      "Epoch 27/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9804 - loss: 0.0577 - val_accuracy: 0.9790 - val_loss: 0.0643\n",
      "Epoch 28/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9856 - loss: 0.0404 - val_accuracy: 0.9828 - val_loss: 0.0515\n",
      "Epoch 29/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0381 - val_accuracy: 0.9854 - val_loss: 0.0430\n",
      "Epoch 30/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9823 - loss: 0.0564 - val_accuracy: 0.9811 - val_loss: 0.0625\n",
      "Epoch 31/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9828 - loss: 0.0498 - val_accuracy: 0.9832 - val_loss: 0.0587\n"
     ]
    }
   ],
   "source": [
    "# Alterating Kernel Size: ###\n",
    "\n",
    "\n",
    "# Modell Input\n",
    "inputs = Input(shape=(187, 1), name=\"Input\")\n",
    "\n",
    "# 1D-CNN Layer\n",
    "first_layer = Conv1D(filters=64, kernel_size=5, activation='relu')   ####\n",
    "second_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# Zweite CNN-Schicht hinzufügen\n",
    "third_layer = Conv1D(filters=128, kernel_size=5, activation='relu')   ####\n",
    "fourth_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(100, return_sequences=False)\n",
    "\n",
    "# Dense Layers\n",
    "dense_layer = Dense(50, activation='relu')\n",
    "dropout_layer = Dropout(0.5)\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Verbindung der Layers\n",
    "x = first_layer(inputs)\n",
    "x = second_layer(x)\n",
    "x = third_layer(x)\n",
    "x = fourth_layer(x)\n",
    "x = lstm_layer(x)\n",
    "x = dense_layer(x)\n",
    "x = dropout_layer(x)\n",
    "outputs = output_layer(x)\n",
    "\n",
    "# Modell erstellen\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "training_history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       827\n",
      "           1       0.98      0.99      0.99      2083\n",
      "\n",
      "    accuracy                           0.98      2910\n",
      "   macro avg       0.98      0.98      0.98      2910\n",
      "weighted avg       0.98      0.98      0.98      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Da die Ausgabe des Modells Wahrscheinlichkeiten zwischen 0 und 1 ist, müssen wir diese in 0 oder 1 umwandeln\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(report)\n",
    "\n",
    "### Results improved further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klassen Anzahl y-train:  {1: 8422, 0: 3218}\n",
      "Klassen Anzahl Oversampled (SMO):  {1: 8422, 0: 8422}\n",
      "Epoch 1/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6771 - loss: 0.5775 - val_accuracy: 0.8596 - val_loss: 0.4852\n",
      "Epoch 2/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8117 - loss: 0.4210 - val_accuracy: 0.8670 - val_loss: 0.3946\n",
      "Epoch 3/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8517 - loss: 0.3586 - val_accuracy: 0.4354 - val_loss: 0.8712\n",
      "Epoch 4/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8628 - loss: 0.3140 - val_accuracy: 0.7465 - val_loss: 0.6689\n",
      "Epoch 5/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8985 - loss: 0.2453 - val_accuracy: 0.9804 - val_loss: 0.0906\n",
      "Epoch 6/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9125 - loss: 0.2198 - val_accuracy: 0.9329 - val_loss: 0.2030\n",
      "Epoch 7/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9266 - loss: 0.1814 - val_accuracy: 0.9478 - val_loss: 0.1336\n",
      "Epoch 8/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9422 - loss: 0.1484 - val_accuracy: 0.9697 - val_loss: 0.0895\n",
      "Epoch 9/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9502 - loss: 0.1485 - val_accuracy: 0.9249 - val_loss: 0.1863\n",
      "Epoch 10/50\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9600 - loss: 0.1116 - val_accuracy: 0.9299 - val_loss: 0.1518\n"
     ]
    }
   ],
   "source": [
    "# With Oversampling with SMOTE\n",
    "\n",
    "smo=SMOTE()\n",
    "X_sm,y_sm = smo.fit_resample(X_train, y_train)\n",
    "print(\"Klassen Anzahl y-train: \", dict(pd.Series(y_train).value_counts()))\n",
    "print(\"Klassen Anzahl Oversampled (SMO): \", dict(pd.Series(y_sm).value_counts()))\n",
    "\n",
    "\n",
    "# Modell Input\n",
    "inputs = Input(shape=(187, 1), name=\"Input\")\n",
    "\n",
    "# 1D-CNN Layer\n",
    "first_layer = Conv1D(filters=64, kernel_size=3, activation='relu')\n",
    "second_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# Zweite CNN-Schicht hinzufügen\n",
    "third_layer = Conv1D(filters=128, kernel_size=3, activation='relu')\n",
    "fourth_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(100, return_sequences=False)\n",
    "\n",
    "# Dense Layers\n",
    "dense_layer = Dense(50, activation='relu')\n",
    "dropout_layer = Dropout(0.5)\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Verbindung der Layers\n",
    "x = first_layer(inputs)\n",
    "x = second_layer(x)\n",
    "x = third_layer(x)\n",
    "x = fourth_layer(x)\n",
    "x = lstm_layer(x)\n",
    "x = dense_layer(x)\n",
    "x = dropout_layer(x)\n",
    "outputs = output_layer(x)\n",
    "\n",
    "# Modell erstellen\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "training_history = model.fit(X_sm, y_sm, validation_split=0.2, epochs=50, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78       827\n",
      "           1       0.98      0.79      0.88      2083\n",
      "\n",
      "    accuracy                           0.84      2910\n",
      "   macro avg       0.82      0.88      0.83      2910\n",
      "weighted avg       0.89      0.84      0.85      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Da die Ausgabe des Modells Wahrscheinlichkeiten zwischen 0 und 1 ist, müssen wir diese in 0 oder 1 umwandeln\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(report)\n",
    "\n",
    "\n",
    "### Results are much Worse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7254 - loss: 0.5759 - val_accuracy: 0.7753 - val_loss: 0.4251\n",
      "Epoch 2/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7853 - loss: 0.4334 - val_accuracy: 0.8106 - val_loss: 0.3828\n",
      "Epoch 3/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8160 - loss: 0.3837 - val_accuracy: 0.7925 - val_loss: 0.4177\n",
      "Epoch 4/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8354 - loss: 0.3714 - val_accuracy: 0.8522 - val_loss: 0.3385\n",
      "Epoch 5/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8463 - loss: 0.3612 - val_accuracy: 0.8634 - val_loss: 0.3116\n",
      "Epoch 6/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8708 - loss: 0.3143 - val_accuracy: 0.8845 - val_loss: 0.2934\n",
      "Epoch 7/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8816 - loss: 0.2806 - val_accuracy: 0.8862 - val_loss: 0.3118\n",
      "Epoch 8/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8952 - loss: 0.2628 - val_accuracy: 0.9068 - val_loss: 0.2316\n",
      "Epoch 9/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9135 - loss: 0.2222 - val_accuracy: 0.8522 - val_loss: 0.3399\n",
      "Epoch 10/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9127 - loss: 0.2138 - val_accuracy: 0.9373 - val_loss: 0.1741\n",
      "Epoch 11/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9191 - loss: 0.1919 - val_accuracy: 0.9197 - val_loss: 0.1964\n",
      "Epoch 12/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9347 - loss: 0.1668 - val_accuracy: 0.9270 - val_loss: 0.1786\n",
      "Epoch 13/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9470 - loss: 0.1400 - val_accuracy: 0.9536 - val_loss: 0.1346\n",
      "Epoch 14/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9515 - loss: 0.1299 - val_accuracy: 0.9545 - val_loss: 0.1186\n",
      "Epoch 15/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9502 - loss: 0.1281 - val_accuracy: 0.9446 - val_loss: 0.1518\n",
      "Epoch 16/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9498 - loss: 0.1391 - val_accuracy: 0.9639 - val_loss: 0.1015\n",
      "Epoch 17/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9655 - loss: 0.1011 - val_accuracy: 0.9579 - val_loss: 0.1091\n",
      "Epoch 18/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9582 - loss: 0.1057 - val_accuracy: 0.9734 - val_loss: 0.0760\n",
      "Epoch 19/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9686 - loss: 0.0873 - val_accuracy: 0.9729 - val_loss: 0.0803\n",
      "Epoch 20/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9710 - loss: 0.0778 - val_accuracy: 0.9751 - val_loss: 0.0698\n",
      "Epoch 21/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9664 - loss: 0.0807 - val_accuracy: 0.9674 - val_loss: 0.0892\n",
      "Epoch 22/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9763 - loss: 0.0708 - val_accuracy: 0.9734 - val_loss: 0.0812\n",
      "Epoch 23/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9746 - loss: 0.0688 - val_accuracy: 0.9734 - val_loss: 0.0745\n",
      "Epoch 24/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9765 - loss: 0.0604 - val_accuracy: 0.9802 - val_loss: 0.0573\n",
      "Epoch 25/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9801 - loss: 0.0609 - val_accuracy: 0.9790 - val_loss: 0.0565\n",
      "Epoch 26/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9827 - loss: 0.0520 - val_accuracy: 0.9764 - val_loss: 0.0572\n",
      "Epoch 27/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9827 - loss: 0.0515 - val_accuracy: 0.9678 - val_loss: 0.0801\n",
      "Epoch 28/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9831 - loss: 0.0450 - val_accuracy: 0.9558 - val_loss: 0.1250\n",
      "Epoch 29/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9806 - loss: 0.0582 - val_accuracy: 0.9734 - val_loss: 0.0877\n"
     ]
    }
   ],
   "source": [
    "# Changing the Position of the Dropout Layer:\n",
    "\n",
    "\n",
    "# Modell Input\n",
    "inputs = Input(shape=(187, 1), name=\"Input\")\n",
    "\n",
    "# 1D-CNN Layer\n",
    "first_layer = Conv1D(filters=64, kernel_size=3, activation='relu')\n",
    "second_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# Zweite CNN-Schicht hinzufügen\n",
    "third_layer = Conv1D(filters=128, kernel_size=3, activation='relu')\n",
    "fourth_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(100, return_sequences=False)\n",
    "dropout_layer = Dropout(0.5)   ####\n",
    "\n",
    "# Dense Layers\n",
    "dense_layer = Dense(50, activation='relu')\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Verbindung der Layers\n",
    "x = first_layer(inputs)\n",
    "x = second_layer(x)\n",
    "x = third_layer(x)\n",
    "x = fourth_layer(x)\n",
    "x = lstm_layer(x)\n",
    "x = dropout_layer(x)   ####\n",
    "x = dense_layer(x)\n",
    "outputs = output_layer(x)\n",
    "\n",
    "# Modell erstellen\n",
    "model1 = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Modell kompilieren\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "training_history = model1.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.97      0.78       827\n",
      "           1       0.98      0.79      0.88      2083\n",
      "\n",
      "    accuracy                           0.84      2910\n",
      "   macro avg       0.82      0.88      0.83      2910\n",
      "weighted avg       0.89      0.84      0.85      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Da die Ausgabe des Modells Wahrscheinlichkeiten zwischen 0 und 1 ist, müssen wir diese in 0 oder 1 umwandeln\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(report)\n",
    "\n",
    "### Results are much worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.7174 - loss: 0.5963 - val_accuracy: 0.7762 - val_loss: 0.4888\n",
      "Epoch 2/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.7743 - loss: 0.4607 - val_accuracy: 0.7818 - val_loss: 0.4097\n",
      "Epoch 3/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.7955 - loss: 0.4276 - val_accuracy: 0.8209 - val_loss: 0.3588\n",
      "Epoch 4/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8245 - loss: 0.3690 - val_accuracy: 0.8222 - val_loss: 0.3388\n",
      "Epoch 5/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.8385 - loss: 0.3404 - val_accuracy: 0.8419 - val_loss: 0.3058\n",
      "Epoch 6/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.8442 - loss: 0.3294 - val_accuracy: 0.8509 - val_loss: 0.2786\n",
      "Epoch 7/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.8650 - loss: 0.2988 - val_accuracy: 0.8896 - val_loss: 0.2462\n",
      "Epoch 8/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.8892 - loss: 0.2625 - val_accuracy: 0.9038 - val_loss: 0.2100\n",
      "Epoch 9/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.9003 - loss: 0.2456 - val_accuracy: 0.9034 - val_loss: 0.2178\n",
      "Epoch 10/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9172 - loss: 0.2155 - val_accuracy: 0.9231 - val_loss: 0.1800\n",
      "Epoch 11/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9246 - loss: 0.1980 - val_accuracy: 0.9188 - val_loss: 0.1940\n",
      "Epoch 12/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9344 - loss: 0.1841 - val_accuracy: 0.9081 - val_loss: 0.2059\n",
      "Epoch 13/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9329 - loss: 0.1743 - val_accuracy: 0.9351 - val_loss: 0.1559\n",
      "Epoch 14/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9326 - loss: 0.1854 - val_accuracy: 0.9485 - val_loss: 0.1314\n",
      "Epoch 15/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9533 - loss: 0.1393 - val_accuracy: 0.8973 - val_loss: 0.2063\n",
      "Epoch 16/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9401 - loss: 0.1609 - val_accuracy: 0.9575 - val_loss: 0.1193\n",
      "Epoch 17/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9550 - loss: 0.1401 - val_accuracy: 0.9540 - val_loss: 0.1147\n",
      "Epoch 18/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9637 - loss: 0.1177 - val_accuracy: 0.9729 - val_loss: 0.0767\n",
      "Epoch 19/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9699 - loss: 0.0941 - val_accuracy: 0.9377 - val_loss: 0.1718\n",
      "Epoch 20/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9643 - loss: 0.1065 - val_accuracy: 0.9171 - val_loss: 0.2551\n",
      "Epoch 21/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9420 - loss: 0.1556 - val_accuracy: 0.9699 - val_loss: 0.0978\n",
      "Epoch 22/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9651 - loss: 0.1080 - val_accuracy: 0.9639 - val_loss: 0.1025\n",
      "Epoch 23/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9686 - loss: 0.1107 - val_accuracy: 0.9759 - val_loss: 0.0724\n",
      "Epoch 24/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9693 - loss: 0.0907 - val_accuracy: 0.9768 - val_loss: 0.0685\n",
      "Epoch 25/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9803 - loss: 0.0730 - val_accuracy: 0.9768 - val_loss: 0.0737\n",
      "Epoch 26/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9760 - loss: 0.0823 - val_accuracy: 0.9738 - val_loss: 0.0689\n",
      "Epoch 27/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9751 - loss: 0.0733 - val_accuracy: 0.9781 - val_loss: 0.0577\n",
      "Epoch 28/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9824 - loss: 0.0602 - val_accuracy: 0.9742 - val_loss: 0.0637\n",
      "Epoch 29/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9839 - loss: 0.0530 - val_accuracy: 0.9863 - val_loss: 0.0491\n",
      "Epoch 30/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9811 - loss: 0.0646 - val_accuracy: 0.9549 - val_loss: 0.1097\n",
      "Epoch 31/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9784 - loss: 0.0699 - val_accuracy: 0.9824 - val_loss: 0.0527\n",
      "Epoch 32/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9811 - loss: 0.0748 - val_accuracy: 0.9725 - val_loss: 0.0878\n",
      "Epoch 33/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9835 - loss: 0.0596 - val_accuracy: 0.9850 - val_loss: 0.0522\n",
      "Epoch 34/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9863 - loss: 0.0397 - val_accuracy: 0.9755 - val_loss: 0.0828\n"
     ]
    }
   ],
   "source": [
    "# Changing Rate of Dropout Layer: ###\n",
    "\n",
    "\n",
    "# Modell Input\n",
    "inputs = Input(shape=(187, 1), name=\"Input\")\n",
    "\n",
    "# 1D-CNN Layer\n",
    "first_layer = Conv1D(filters=64, kernel_size=3, activation='relu')\n",
    "second_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# Zweite CNN-Schicht hinzufügen\n",
    "third_layer = Conv1D(filters=128, kernel_size=3, activation='relu')\n",
    "fourth_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(100, return_sequences=False)\n",
    "\n",
    "# Dense Layers\n",
    "dense_layer = Dense(50, activation='relu')\n",
    "dropout_layer = Dropout(0.8)     ####\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Verbindung der Layers\n",
    "x = first_layer(inputs)\n",
    "x = second_layer(x)\n",
    "x = third_layer(x)\n",
    "x = fourth_layer(x)\n",
    "x = lstm_layer(x)\n",
    "x = dense_layer(x)\n",
    "x = dropout_layer(x)\n",
    "outputs = output_layer(x)\n",
    "\n",
    "# Modell erstellen\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "training_history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       827\n",
      "           1       0.98      0.99      0.99      2083\n",
      "\n",
      "    accuracy                           0.98      2910\n",
      "   macro avg       0.98      0.98      0.98      2910\n",
      "weighted avg       0.98      0.98      0.98      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Da die Ausgabe des Modells Wahrscheinlichkeiten zwischen 0 und 1 ist, müssen wir diese in 0 oder 1 umwandeln\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(report)\n",
    "\n",
    "### Greatly improved Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.7410 - loss: 0.5592 - val_accuracy: 0.7947 - val_loss: 0.4468\n",
      "Epoch 2/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8075 - loss: 0.4313 - val_accuracy: 0.8015 - val_loss: 0.4010\n",
      "Epoch 3/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8232 - loss: 0.3819 - val_accuracy: 0.8273 - val_loss: 0.3598\n",
      "Epoch 4/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8567 - loss: 0.3363 - val_accuracy: 0.8621 - val_loss: 0.3110\n",
      "Epoch 5/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8674 - loss: 0.3026 - val_accuracy: 0.8969 - val_loss: 0.2583\n",
      "Epoch 6/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8944 - loss: 0.2544 - val_accuracy: 0.9175 - val_loss: 0.2275\n",
      "Epoch 7/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9063 - loss: 0.2321 - val_accuracy: 0.9068 - val_loss: 0.2471\n",
      "Epoch 8/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9205 - loss: 0.2124 - val_accuracy: 0.9364 - val_loss: 0.1503\n",
      "Epoch 9/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9365 - loss: 0.1691 - val_accuracy: 0.9356 - val_loss: 0.1577\n",
      "Epoch 10/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9467 - loss: 0.1440 - val_accuracy: 0.9562 - val_loss: 0.1170\n",
      "Epoch 11/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9550 - loss: 0.1243 - val_accuracy: 0.9596 - val_loss: 0.0964\n",
      "Epoch 12/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9505 - loss: 0.1284 - val_accuracy: 0.9424 - val_loss: 0.1381\n",
      "Epoch 13/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9618 - loss: 0.1048 - val_accuracy: 0.9613 - val_loss: 0.0980\n",
      "Epoch 14/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9614 - loss: 0.1082 - val_accuracy: 0.9493 - val_loss: 0.1324\n",
      "Epoch 15/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9652 - loss: 0.0989 - val_accuracy: 0.9536 - val_loss: 0.1072\n",
      "Epoch 16/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9727 - loss: 0.0751 - val_accuracy: 0.9631 - val_loss: 0.0895\n",
      "Epoch 17/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9717 - loss: 0.0828 - val_accuracy: 0.9738 - val_loss: 0.0702\n",
      "Epoch 18/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9663 - loss: 0.0934 - val_accuracy: 0.9691 - val_loss: 0.0871\n",
      "Epoch 19/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9712 - loss: 0.0776 - val_accuracy: 0.9790 - val_loss: 0.0714\n",
      "Epoch 20/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9799 - loss: 0.0620 - val_accuracy: 0.9669 - val_loss: 0.0894\n",
      "Epoch 21/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9783 - loss: 0.0603 - val_accuracy: 0.9738 - val_loss: 0.0763\n",
      "Epoch 22/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9751 - loss: 0.0659 - val_accuracy: 0.9708 - val_loss: 0.0784\n",
      "Epoch 23/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9818 - loss: 0.0537 - val_accuracy: 0.9811 - val_loss: 0.0704\n",
      "Epoch 24/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9808 - loss: 0.0576 - val_accuracy: 0.9815 - val_loss: 0.0567\n",
      "Epoch 25/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9821 - loss: 0.0510 - val_accuracy: 0.9790 - val_loss: 0.0707\n",
      "Epoch 26/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9762 - loss: 0.0658 - val_accuracy: 0.9863 - val_loss: 0.0426\n",
      "Epoch 27/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9833 - loss: 0.0487 - val_accuracy: 0.9755 - val_loss: 0.0762\n",
      "Epoch 28/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9874 - loss: 0.0378 - val_accuracy: 0.9858 - val_loss: 0.0436\n",
      "Epoch 29/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9886 - loss: 0.0315 - val_accuracy: 0.9790 - val_loss: 0.0639\n",
      "Epoch 30/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9868 - loss: 0.0391 - val_accuracy: 0.9781 - val_loss: 0.0738\n",
      "Epoch 31/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9889 - loss: 0.0344 - val_accuracy: 0.9639 - val_loss: 0.0928\n"
     ]
    }
   ],
   "source": [
    "# Change of Batch Size: \n",
    "\n",
    "\n",
    "# Modell Input\n",
    "inputs = Input(shape=(187, 1), name=\"Input\")\n",
    "\n",
    "# 1D-CNN Layer\n",
    "first_layer = Conv1D(filters=64, kernel_size=3, activation='relu')\n",
    "second_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# Zweite CNN-Schicht hinzufügen\n",
    "third_layer = Conv1D(filters=128, kernel_size=3, activation='relu')\n",
    "fourth_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(100, return_sequences=False)\n",
    "\n",
    "# Dense Layers\n",
    "dense_layer = Dense(50, activation='relu')\n",
    "dropout_layer = Dropout(0.5)   \n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Verbindung der Layers\n",
    "x = first_layer(inputs)\n",
    "x = second_layer(x)\n",
    "x = third_layer(x)\n",
    "x = fourth_layer(x)\n",
    "x = lstm_layer(x)\n",
    "x = dense_layer(x)\n",
    "x = dropout_layer(x)\n",
    "outputs = output_layer(x)\n",
    "\n",
    "# Modell erstellen\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "training_history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=16, callbacks=[early_stopping])  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       827\n",
      "           1       0.98      0.99      0.99      2083\n",
      "\n",
      "    accuracy                           0.98      2910\n",
      "   macro avg       0.98      0.97      0.98      2910\n",
      "weighted avg       0.98      0.98      0.98      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Da die Ausgabe des Modells Wahrscheinlichkeiten zwischen 0 und 1 ist, müssen wir diese in 0 oder 1 umwandeln\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(report)\n",
    "\n",
    "### Greatly improved Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.7380 - loss: 0.5650 - val_accuracy: 0.7955 - val_loss: 0.4418\n",
      "Epoch 2/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8119 - loss: 0.4156 - val_accuracy: 0.8174 - val_loss: 0.3871\n",
      "Epoch 3/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8294 - loss: 0.3778 - val_accuracy: 0.8338 - val_loss: 0.3851\n",
      "Epoch 4/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8471 - loss: 0.3450 - val_accuracy: 0.7848 - val_loss: 0.4181\n",
      "Epoch 5/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8691 - loss: 0.3038 - val_accuracy: 0.8845 - val_loss: 0.3274\n",
      "Epoch 6/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8940 - loss: 0.2611 - val_accuracy: 0.8694 - val_loss: 0.2888\n",
      "Epoch 7/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8873 - loss: 0.2652 - val_accuracy: 0.8673 - val_loss: 0.2975\n",
      "Epoch 8/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9081 - loss: 0.2186 - val_accuracy: 0.9317 - val_loss: 0.1714\n",
      "Epoch 9/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9251 - loss: 0.1871 - val_accuracy: 0.9180 - val_loss: 0.2051\n",
      "Epoch 10/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9215 - loss: 0.1853 - val_accuracy: 0.9313 - val_loss: 0.1592\n",
      "Epoch 11/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9423 - loss: 0.1487 - val_accuracy: 0.9442 - val_loss: 0.1388\n",
      "Epoch 12/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9289 - loss: 0.1706 - val_accuracy: 0.9515 - val_loss: 0.1265\n",
      "Epoch 13/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9518 - loss: 0.1289 - val_accuracy: 0.9437 - val_loss: 0.1264\n",
      "Epoch 14/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9522 - loss: 0.1282 - val_accuracy: 0.9566 - val_loss: 0.1104\n",
      "Epoch 15/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9547 - loss: 0.1174 - val_accuracy: 0.9588 - val_loss: 0.1088\n",
      "Epoch 16/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9611 - loss: 0.1005 - val_accuracy: 0.9596 - val_loss: 0.1016\n",
      "Epoch 17/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9648 - loss: 0.0971 - val_accuracy: 0.9502 - val_loss: 0.1249\n",
      "Epoch 18/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9593 - loss: 0.1118 - val_accuracy: 0.9579 - val_loss: 0.1136\n",
      "Epoch 19/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9670 - loss: 0.0941 - val_accuracy: 0.9588 - val_loss: 0.1042\n",
      "Epoch 20/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9722 - loss: 0.0803 - val_accuracy: 0.9747 - val_loss: 0.0615\n",
      "Epoch 21/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9675 - loss: 0.0819 - val_accuracy: 0.9772 - val_loss: 0.0655\n",
      "Epoch 22/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9753 - loss: 0.0655 - val_accuracy: 0.9738 - val_loss: 0.0815\n",
      "Epoch 23/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9789 - loss: 0.0640 - val_accuracy: 0.9618 - val_loss: 0.1156\n",
      "Epoch 24/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9733 - loss: 0.0746 - val_accuracy: 0.9691 - val_loss: 0.0745\n",
      "Epoch 25/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9764 - loss: 0.0642 - val_accuracy: 0.9845 - val_loss: 0.0474\n",
      "Epoch 26/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9817 - loss: 0.0509 - val_accuracy: 0.9588 - val_loss: 0.1000\n",
      "Epoch 27/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9790 - loss: 0.0596 - val_accuracy: 0.9794 - val_loss: 0.0631\n",
      "Epoch 28/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9782 - loss: 0.0618 - val_accuracy: 0.9785 - val_loss: 0.0658\n",
      "Epoch 29/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9819 - loss: 0.0515 - val_accuracy: 0.9704 - val_loss: 0.0755\n",
      "Epoch 30/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9832 - loss: 0.0540 - val_accuracy: 0.9820 - val_loss: 0.0605\n"
     ]
    }
   ],
   "source": [
    "# Change of Neurons in Dense Layer:\n",
    "\n",
    "# Modell Input\n",
    "inputs = Input(shape=(187, 1), name=\"Input\")\n",
    "\n",
    "# 1D-CNN Layer\n",
    "first_layer = Conv1D(filters=64, kernel_size=3, activation='relu')\n",
    "second_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# Zweite CNN-Schicht hinzufügen\n",
    "third_layer = Conv1D(filters=128, kernel_size=3, activation='relu')\n",
    "fourth_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(100, return_sequences=False)\n",
    "\n",
    "# Dense Layers\n",
    "dense_layer = Dense(100, activation='relu') ###\n",
    "dropout_layer = Dropout(0.5)   \n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Verbindung der Layers\n",
    "x = first_layer(inputs)\n",
    "x = second_layer(x)\n",
    "x = third_layer(x)\n",
    "x = fourth_layer(x)\n",
    "x = lstm_layer(x)\n",
    "x = dense_layer(x)\n",
    "x = dropout_layer(x)\n",
    "outputs = output_layer(x)\n",
    "\n",
    "# Modell erstellen\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "training_history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       827\n",
      "           1       0.98      0.99      0.99      2083\n",
      "\n",
      "    accuracy                           0.98      2910\n",
      "   macro avg       0.98      0.97      0.98      2910\n",
      "weighted avg       0.98      0.98      0.98      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Da die Ausgabe des Modells Wahrscheinlichkeiten zwischen 0 und 1 ist, müssen wir diese in 0 oder 1 umwandeln\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(report)\n",
    "\n",
    "### Improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusive Model of this Exploration:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.7100 - loss: 0.5842 - val_accuracy: 0.8037 - val_loss: 0.4243\n",
      "Epoch 2/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8199 - loss: 0.4101 - val_accuracy: 0.8183 - val_loss: 0.3777\n",
      "Epoch 3/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8531 - loss: 0.3529 - val_accuracy: 0.9094 - val_loss: 0.2340\n",
      "Epoch 4/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8895 - loss: 0.2767 - val_accuracy: 0.9128 - val_loss: 0.2163\n",
      "Epoch 5/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9156 - loss: 0.2269 - val_accuracy: 0.9248 - val_loss: 0.1875\n",
      "Epoch 6/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9205 - loss: 0.2142 - val_accuracy: 0.8638 - val_loss: 0.3170\n",
      "Epoch 7/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9305 - loss: 0.1929 - val_accuracy: 0.9429 - val_loss: 0.1513\n",
      "Epoch 8/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9427 - loss: 0.1563 - val_accuracy: 0.9497 - val_loss: 0.1372\n",
      "Epoch 9/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9457 - loss: 0.1472 - val_accuracy: 0.9575 - val_loss: 0.1183\n",
      "Epoch 10/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9511 - loss: 0.1293 - val_accuracy: 0.9356 - val_loss: 0.1905\n",
      "Epoch 11/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.9561 - loss: 0.1264 - val_accuracy: 0.9639 - val_loss: 0.0934\n",
      "Epoch 12/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9630 - loss: 0.1073 - val_accuracy: 0.9562 - val_loss: 0.1326\n",
      "Epoch 13/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9668 - loss: 0.1002 - val_accuracy: 0.8595 - val_loss: 0.3345\n",
      "Epoch 14/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9613 - loss: 0.1049 - val_accuracy: 0.9704 - val_loss: 0.0838\n",
      "Epoch 15/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9639 - loss: 0.1061 - val_accuracy: 0.9721 - val_loss: 0.0818\n",
      "Epoch 16/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9708 - loss: 0.0883 - val_accuracy: 0.9678 - val_loss: 0.0916\n",
      "Epoch 17/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9762 - loss: 0.0678 - val_accuracy: 0.9777 - val_loss: 0.0638\n",
      "Epoch 18/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.9771 - loss: 0.0687 - val_accuracy: 0.9609 - val_loss: 0.1422\n",
      "Epoch 19/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9720 - loss: 0.0799 - val_accuracy: 0.9635 - val_loss: 0.1113\n",
      "Epoch 20/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 30ms/step - accuracy: 0.9780 - loss: 0.0636 - val_accuracy: 0.9772 - val_loss: 0.0682\n",
      "Epoch 21/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9840 - loss: 0.0501 - val_accuracy: 0.9837 - val_loss: 0.0648\n",
      "Epoch 22/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 32ms/step - accuracy: 0.9800 - loss: 0.0653 - val_accuracy: 0.9858 - val_loss: 0.0534\n",
      "Epoch 23/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 26ms/step - accuracy: 0.9859 - loss: 0.0410 - val_accuracy: 0.9785 - val_loss: 0.0980\n",
      "Epoch 24/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9778 - loss: 0.0655 - val_accuracy: 0.9863 - val_loss: 0.0414\n",
      "Epoch 25/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.0458 - val_accuracy: 0.9854 - val_loss: 0.0517\n",
      "Epoch 26/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9878 - loss: 0.0389 - val_accuracy: 0.9880 - val_loss: 0.0335\n",
      "Epoch 27/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9873 - loss: 0.0392 - val_accuracy: 0.9768 - val_loss: 0.0659\n",
      "Epoch 28/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0401 - val_accuracy: 0.9828 - val_loss: 0.0618\n",
      "Epoch 29/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9891 - loss: 0.0319 - val_accuracy: 0.9880 - val_loss: 0.0429\n",
      "Epoch 30/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9899 - loss: 0.0311 - val_accuracy: 0.9880 - val_loss: 0.0351\n",
      "Epoch 31/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9921 - loss: 0.0294 - val_accuracy: 0.9725 - val_loss: 0.0855\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Modell Input\n",
    "inputs = Input(shape=(187, 1), name=\"Input\")\n",
    "\n",
    "# 1D-CNN Layer\n",
    "first_layer = Conv1D(filters=64, kernel_size=5, activation='relu')\n",
    "second_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# Zweite CNN-Schicht hinzufügen\n",
    "third_layer = Conv1D(filters=128, kernel_size=7, activation='relu')\n",
    "fourth_layer = MaxPooling1D(pool_size=2)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(100, return_sequences=False)\n",
    "\n",
    "# Dense Layers\n",
    "dense_layer = Dense(100, activation='relu')\n",
    "dropout_layer = Dropout(0.8)\n",
    "output_layer = Dense(1, activation='sigmoid')\n",
    "\n",
    "# Verbindung der Layers\n",
    "x = first_layer(inputs)\n",
    "x = second_layer(x)\n",
    "x = third_layer(x)\n",
    "x = fourth_layer(x)\n",
    "x = lstm_layer(x)\n",
    "x = dense_layer(x)\n",
    "x = dropout_layer(x)\n",
    "outputs = output_layer(x)\n",
    "\n",
    "# Modell erstellen\n",
    "model1 = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Modell kompilieren\n",
    "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "training_history = model1.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=16, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       809\n",
      "           1       0.99      0.99      0.99      2101\n",
      "\n",
      "    accuracy                           0.99      2910\n",
      "   macro avg       0.99      0.99      0.99      2910\n",
      "weighted avg       0.99      0.99      0.99      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "# Da die Ausgabe des Modells Wahrscheinlichkeiten zwischen 0 und 1 ist, müssen wir diese in 0 oder 1 umwandeln\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Final Model of first Attempt!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Attempt with Batch Normalization ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_31\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_31\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">185</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">92</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">91,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_62 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m185\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_62 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m92\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_63 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m24,704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_63 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_31 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m91,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_62 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m5,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_63 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,429</span> (478.24 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m122,429\u001b[0m (478.24 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">122,045</span> (476.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m122,045\u001b[0m (476.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.7432 - loss: 0.5244 - val_accuracy: 0.7174 - val_loss: 0.5996\n",
      "Epoch 2/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8674 - loss: 0.3294 - val_accuracy: 0.6482 - val_loss: 0.6097\n",
      "Epoch 3/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.8911 - loss: 0.2556 - val_accuracy: 0.8333 - val_loss: 0.4227\n",
      "Epoch 4/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9269 - loss: 0.1932 - val_accuracy: 0.8329 - val_loss: 0.4395\n",
      "Epoch 5/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9463 - loss: 0.1521 - val_accuracy: 0.7393 - val_loss: 1.0173\n",
      "Epoch 6/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9570 - loss: 0.1253 - val_accuracy: 0.8930 - val_loss: 0.2610\n",
      "Epoch 7/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9679 - loss: 0.0968 - val_accuracy: 0.8101 - val_loss: 0.6048\n",
      "Epoch 8/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9710 - loss: 0.0885 - val_accuracy: 0.9399 - val_loss: 0.1665\n",
      "Epoch 9/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9786 - loss: 0.0745 - val_accuracy: 0.8690 - val_loss: 0.3128\n",
      "Epoch 10/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9838 - loss: 0.0586 - val_accuracy: 0.9192 - val_loss: 0.2947\n",
      "Epoch 11/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9833 - loss: 0.0604 - val_accuracy: 0.9751 - val_loss: 0.0878\n",
      "Epoch 12/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9811 - loss: 0.0599 - val_accuracy: 0.7710 - val_loss: 1.1430\n",
      "Epoch 13/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9860 - loss: 0.0451 - val_accuracy: 0.8849 - val_loss: 0.3345\n",
      "Epoch 14/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9795 - loss: 0.0560 - val_accuracy: 0.7741 - val_loss: 1.3020\n",
      "Epoch 15/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9855 - loss: 0.0467 - val_accuracy: 0.9523 - val_loss: 0.1406\n",
      "Epoch 16/50\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.9869 - loss: 0.0421 - val_accuracy: 0.7225 - val_loss: 1.5290\n"
     ]
    }
   ],
   "source": [
    "# Second Attempt: \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Modell Input\n",
    "inputs = Input(shape=(187, 1), name=\"Input\")\n",
    "\n",
    "# 1D-CNN Layer mit Batch Normalization\n",
    "first_layer = Conv1D(filters=64, kernel_size=3, activation='relu')(inputs)\n",
    "second_layer = BatchNormalization()(first_layer)\n",
    "third_layer = MaxPooling1D(pool_size=2)(second_layer)\n",
    "\n",
    "# Zweite CNN-Schicht hinzufügen\n",
    "fourth_layer = Conv1D(filters=128, kernel_size=3, activation='relu')(third_layer)\n",
    "fifth_layer = BatchNormalization()(fourth_layer)\n",
    "sixth_layer = MaxPooling1D(pool_size=2)(fifth_layer)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(100, return_sequences=False)(sixth_layer)\n",
    "\n",
    "# Dense Layers\n",
    "dense_layer = Dense(50, activation='relu')(lstm_layer)\n",
    "dropout_layer = Dropout(0.5)(dense_layer)\n",
    "\n",
    "# Output Layer (binäre Klassifikation)\n",
    "outputs = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "# Modell erstellen\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Modell-Übersicht anzeigen\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "# Modell trainieren\n",
    "training_history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=32, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       827\n",
      "           1       0.98      0.99      0.98      2083\n",
      "\n",
      "    accuracy                           0.97      2910\n",
      "   macro avg       0.97      0.97      0.97      2910\n",
      "weighted avg       0.97      0.97      0.97      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Da die Ausgabe des Modells Wahrscheinlichkeiten zwischen 0 und 1 ist, müssen wir diese in 0 oder 1 umwandeln\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_33\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_33\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">183</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">57,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">91,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_66 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m183\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m183\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_66 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_67 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m57,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_67 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_33 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m91,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_66 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_33 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,425</span> (626.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m160,425\u001b[0m (626.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,041</span> (625.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m160,041\u001b[0m (625.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.7631 - loss: 0.5226 - val_accuracy: 0.7255 - val_loss: 0.7551\n",
      "Epoch 2/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8793 - loss: 0.3040 - val_accuracy: 0.7350 - val_loss: 0.9328\n",
      "Epoch 3/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9123 - loss: 0.2361 - val_accuracy: 0.8385 - val_loss: 0.5076\n",
      "Epoch 4/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9439 - loss: 0.1672 - val_accuracy: 0.6697 - val_loss: 1.0731\n",
      "Epoch 5/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9570 - loss: 0.1318 - val_accuracy: 0.8759 - val_loss: 0.3972\n",
      "Epoch 6/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9657 - loss: 0.1157 - val_accuracy: 0.9566 - val_loss: 0.1299\n",
      "Epoch 7/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9712 - loss: 0.0944 - val_accuracy: 0.8557 - val_loss: 0.5389\n",
      "Epoch 8/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9727 - loss: 0.0879 - val_accuracy: 0.6529 - val_loss: 1.5718\n",
      "Epoch 9/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9742 - loss: 0.0901 - val_accuracy: 0.8960 - val_loss: 0.3724\n",
      "Epoch 10/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0651 - val_accuracy: 0.9712 - val_loss: 0.0799\n",
      "Epoch 11/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9794 - loss: 0.0652 - val_accuracy: 0.8303 - val_loss: 0.4372\n",
      "Epoch 12/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9831 - loss: 0.0592 - val_accuracy: 0.9721 - val_loss: 0.0867\n",
      "Epoch 13/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9800 - loss: 0.0626 - val_accuracy: 0.9094 - val_loss: 0.3562\n",
      "Epoch 14/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0519 - val_accuracy: 0.7998 - val_loss: 0.9411\n",
      "Epoch 15/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9846 - loss: 0.0487 - val_accuracy: 0.7775 - val_loss: 1.2108\n",
      "Epoch 16/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9883 - loss: 0.0377 - val_accuracy: 0.9794 - val_loss: 0.0696\n",
      "Epoch 17/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9875 - loss: 0.0443 - val_accuracy: 0.9807 - val_loss: 0.1152\n",
      "Epoch 18/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9922 - loss: 0.0347 - val_accuracy: 0.9652 - val_loss: 0.1171\n",
      "Epoch 19/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9925 - loss: 0.0277 - val_accuracy: 0.9686 - val_loss: 0.1409\n",
      "Epoch 20/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9878 - loss: 0.0465 - val_accuracy: 0.9579 - val_loss: 0.1813\n",
      "Epoch 21/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9910 - loss: 0.0321 - val_accuracy: 0.9424 - val_loss: 0.2378\n",
      "Epoch 22/50\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9962 - loss: 0.0184 - val_accuracy: 0.6319 - val_loss: 1.7795\n"
     ]
    }
   ],
   "source": [
    "# Second Attempt: \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Modell Input\n",
    "inputs = Input(shape=(187, 1), name=\"Input\")\n",
    "\n",
    "# 1D-CNN Layer mit Batch Normalization\n",
    "first_layer = Conv1D(filters=64, kernel_size=5, activation='relu')(inputs)\n",
    "second_layer = BatchNormalization()(first_layer)\n",
    "third_layer = MaxPooling1D(pool_size=2)(second_layer)\n",
    "\n",
    "# Zweite CNN-Schicht hinzufügen\n",
    "fourth_layer = Conv1D(filters=128, kernel_size=7, activation='relu')(third_layer)\n",
    "fifth_layer = BatchNormalization()(fourth_layer)\n",
    "sixth_layer = MaxPooling1D(pool_size=2)(fifth_layer)\n",
    "\n",
    "# LSTM Layer\n",
    "lstm_layer = LSTM(100, return_sequences=False)(sixth_layer)\n",
    "\n",
    "# Dense Layers\n",
    "dense_layer = Dense(100, activation='relu')(lstm_layer)\n",
    "dropout_layer = Dropout(0.8)(dense_layer)\n",
    "\n",
    "# Output Layer (binäre Klassifikation)\n",
    "outputs = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "# Modell erstellen\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Modell kompilieren\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Modell-Übersicht anzeigen\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "# Modell trainieren\n",
    "training_history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=16, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       827\n",
      "           1       0.98      0.98      0.98      2083\n",
      "\n",
      "    accuracy                           0.97      2910\n",
      "   macro avg       0.97      0.97      0.97      2910\n",
      "weighted avg       0.97      0.97      0.97      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Da die Ausgabe des Modells Wahrscheinlichkeiten zwischen 0 und 1 ist, müssen wir diese in 0 oder 1 umwandeln\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test, y_pred_binary)\n",
    "\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
