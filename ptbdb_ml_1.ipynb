{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **First ML-Algorithms - PTBDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages and Data\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "\n",
    "ptbdb_abnormal_df = pd.read_csv(\"ptbdb_abnormal.csv\")\n",
    "ptbdb_normal_df = pd.read_csv(\"ptbdb_normal.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188\n",
       "1    10505\n",
       "0     4045\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming the Columns\n",
    "new_column_names = range(1, len(ptbdb_normal_df.columns) + 1)\n",
    "ptbdb_normal_df.columns = new_column_names\n",
    "\n",
    "new_column_names = range(1, len(ptbdb_abnormal_df.columns) + 1)\n",
    "ptbdb_abnormal_df.columns = new_column_names\n",
    "\n",
    "# Combining the two Dataframes \n",
    "ptbdb_comb_df = pd.concat([ptbdb_normal_df, ptbdb_abnormal_df], ignore_index=True)\n",
    "\n",
    "# Transforming the Target Variable to Integer\n",
    "ptbdb_comb_df[188]=ptbdb_comb_df[188].astype(int)\n",
    "\n",
    "ptbdb_comb_df[188].value_counts()\n",
    "#ptbdb_comb_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ML-Packages\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler,  ClusterCentroids\n",
    "from imblearn.metrics import classification_report_imbalanced, geometric_mean_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing with optional Standard-Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing, Abnormal == 1\n",
    "\n",
    "ptbdb_comb_df[188] =ptbdb_comb_df[188].replace({0: 1, 1:0})\n",
    "\n",
    "feats = ptbdb_comb_df.drop(188, axis = 1)\n",
    "target = ptbdb_comb_df[188]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size= 0.2, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Simple SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kreuzvalidierungs-Genauigkeit: 0.90 +/- 0.01\n",
      "Verwendeter gamma-Wert: 0.11473276029088923\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma = \"scale\")\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(svm, X_train, y_train, cv=5)\n",
    "print(f\"Kreuzvalidierungs-Genauigkeit: {scores.mean():.2f} +/- {scores.std():.2f}\")\n",
    "\n",
    "print(f\"Verwendeter gamma-Wert: {svm._gamma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions     0    1\n",
      "Reality               \n",
      "0            1992  109\n",
      "1             142  667 \n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.93      0.95      0.82      0.94      0.88      0.79      2101\n",
      "          1       0.86      0.82      0.95      0.84      0.88      0.77       809\n",
      "\n",
      "avg / total       0.91      0.91      0.86      0.91      0.88      0.79      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "print(pd.crosstab(y_test, y_pred, colnames = [\"Predictions\"], rownames = [\"Reality\"]), \"\\n\")\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Most important metric to optimize: Recall\n",
    "- With SC: pre 0.88, rec 0.87\n",
    "- Without SC: pre 86, rec 0.82 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Undersampling with Cluster Centroids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klassenverteilung CC : {0: np.int64(3236), 1: np.int64(3236)}\n"
     ]
    }
   ],
   "source": [
    "cc = ClusterCentroids()\n",
    "X_cc, y_cc = cc.fit_resample(X_train, y_train)\n",
    "print('Klassenverteilung CC :', dict(pd.Series(y_cc).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions     0    1\n",
      "Reality               \n",
      "0            1645  456\n",
      "1              30  779 \n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.98      0.78      0.96      0.87      0.87      0.74      2101\n",
      "          1       0.63      0.96      0.78      0.76      0.87      0.77       809\n",
      "\n",
      "avg / total       0.88      0.83      0.91      0.84      0.87      0.75      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='scale')\n",
    "svm.fit(X_cc, y_cc)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "print(pd.crosstab(y_test, y_pred, colnames = [\"Predictions\"], rownames = [\"Reality\"]), \"\\n\")\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The recall is good - yet the precision lacks significantly\n",
    "- With SC: pre 0.63, rec 0.96\n",
    "- Without SC: pre 0.63, rec 0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Oversampling with SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klassen Anzahl Oversampled (SMO):  {0: np.int64(8404), 1: np.int64(8404)}\n"
     ]
    }
   ],
   "source": [
    "smo=SMOTE()\n",
    "X_sm,y_sm = smo.fit_resample(X_train, y_train)\n",
    "print(\"Klassen Anzahl Oversampled (SMO): \", dict(pd.Series(y_sm).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions     0    1\n",
      "Reality               \n",
      "0            1839  262\n",
      "1              35  774 \n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.98      0.88      0.96      0.93      0.92      0.83      2101\n",
      "          1       0.75      0.96      0.88      0.84      0.92      0.84       809\n",
      "\n",
      "avg / total       0.92      0.90      0.93      0.90      0.92      0.83      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma = \"scale\")\n",
    "svm.fit(X_sm, y_sm)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(pd.crosstab(y_test, y_pred, rownames = [\"Reality\"], colnames = [\"Predictions\"]), \"\\n\")\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In comparison to the undersampling with CC the Precision is better, the recall is comparable\n",
    "- With SC: pre 0.78, rec 0.95\n",
    "- Without SC: 0.75, rec 0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SVM with SMOTE and decreased probability threshold (0.4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.98      0.89      0.95      0.93      0.92      0.84      2101\n",
      "          1       0.76      0.95      0.89      0.85      0.92      0.85       809\n",
      "\n",
      "avg / total       0.92      0.90      0.94      0.91      0.92      0.84      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# since the most promising values so far came with oversampling with SMOTE I used SMOTE for this Model\n",
    "\n",
    "svm = SVC(probability=True, gamma='scale') \n",
    "svm.fit(X_sm, y_sm)                        \n",
    "\n",
    "threshold = 0.4 \n",
    "\n",
    "probs = svm.predict_proba(X_test)\n",
    "\n",
    "pred_class = (probs[:,1]>=threshold).astype('int')\n",
    "\n",
    "pd.crosstab(y_test, pred_class)\n",
    "print(\"\\n\")\n",
    "print(classification_report_imbalanced(y_test, pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Depending on the value for threshold the recall can be increased significantly, yet at cost of the precision.\n",
    "- With SC: prec 0.78, rec 0.95\n",
    "- Without SC: prec 0.76, rec 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Balanced Random Forest Classifier - !!!** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxgl\\heartbeat_dst\\myenv\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "c:\\Users\\maxgl\\heartbeat_dst\\myenv\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "c:\\Users\\maxgl\\heartbeat_dst\\myenv\\lib\\site-packages\\imblearn\\ensemble\\_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      0.95      0.98      0.97      0.96      0.92      2101\n",
      "          1       0.87      0.98      0.95      0.92      0.96      0.93       809\n",
      "\n",
      "avg / total       0.96      0.95      0.97      0.95      0.96      0.92      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "bclf = BalancedRandomForestClassifier()\n",
    "bclf.fit(X_train, y_train) \n",
    "y_pred = bclf.predict(X_test)\n",
    "pd.crosstab(y_test, y_pred)\n",
    "print(\"\\n\")\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Extremely good results!**\n",
    "- With SC: prec 0.88, rec 0.98\n",
    "- Without SC: prec 0.87, rec 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Different ML-Algorithms with external Cross-Validation of Hyperparameters**\n",
    "- Preprocessing with CC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_jobs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m clf_svc \u001b[38;5;241m=\u001b[39m SVC(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m22\u001b[39m)\n\u001b[0;32m      5\u001b[0m param_grid_lr \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m9\u001b[39m)}\n\u001b[0;32m      7\u001b[0m param_grid_rf \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m500\u001b[39m], \n\u001b[0;32m      8\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m], \n\u001b[0;32m      9\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog2\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m---> 10\u001b[0m                   \u001b[43mn_jobs\u001b[49m : \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m}]\n\u001b[0;32m     12\u001b[0m param_grid_svc \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrbf\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m9\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m)},\n\u001b[0;32m     13\u001b[0m                   {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m9\u001b[39m)}]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_jobs' is not defined"
     ]
    }
   ],
   "source": [
    "clf_lr = LogisticRegression(random_state=22, max_iter=2000)\n",
    "clf_rf = RandomForestClassifier(random_state=22)\n",
    "clf_svc = SVC(random_state=22)\n",
    "\n",
    "param_grid_lr = {'solver': ['liblinear', 'lbfgs'], 'C': np.logspace(-4, 2, 9)}\n",
    "\n",
    "param_grid_rf = [{'n_estimators': [10, 50, 100, 500], \n",
    "                  'min_samples_leaf': [1, 3, 5], \n",
    "                  'max_features': ['sqrt', 'log2'], \n",
    "                  n_jobs : -1}]\n",
    "\n",
    "param_grid_svc = [{'kernel': ['rbf'], 'C': np.logspace(-4, 4, 9), 'gamma': np.logspace(-4, 0, 4)},\n",
    "                  {'kernel': ['linear'], 'C': np.logspace(-4, 4, 9)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridcvs = {}\n",
    "\n",
    "for pgrid, clf, name in zip((param_grid_lr, param_grid_rf, param_grid_svc),\n",
    "                            (clf_lr, clf_rf, clf_svc),\n",
    "                            ('LogisticRegression', 'RF', 'SVM')):\n",
    "    gcv = GridSearchCV(clf, pgrid, cv=3, refit=True, scoring='recall', n_jobs = -1)\n",
    "    gridcvs[name] = gcv\n",
    "    \n",
    "print(gridcvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "outer_cv = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "outer_scores = {}\n",
    "\n",
    "for name, gs in gridcvs.items():\n",
    "    # Perform cross-validation and calculate recall\n",
    "    cv_results = cross_validate(gs, X_cc, y_cc, cv=outer_cv, scoring='recall', return_estimator=True, return_train_score=False)\n",
    "    \n",
    "    nested_score = cv_results['test_score']\n",
    "    outer_scores[name] = nested_score\n",
    "    print(f'{name}: outer recall score {100*nested_score.mean():.2f} +/- {100*nested_score.std():.2f}', \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LogisticRegression: outer recall score 76.76 +/- 1.37\n",
    "- RF: outer recall score 93.60 +/- 0.99 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "final_clf = gridcvs['LogisticRegression']\n",
    "final_clf.fit(X_sm, y_sm)\n",
    "y_pred = final_clf.predict(X_test)\n",
    "\n",
    "print(f'Best Parameters: {final_clf.best_params_}, \"\\n\"')\n",
    "\n",
    "pd.crosstab(y_test, y_pred)\n",
    "print(\"\\n\")\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SVM - Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Isolation Forest - Outlier Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Preprocessing, Abnormal == -1\n",
    "\n",
    "ptbdb_comb_df[188] =ptbdb_comb_df[188].replace({0: -1, 1:1})\n",
    "\n",
    "feats = ptbdb_comb_df.drop(188, axis = 1)\n",
    "target = ptbdb_comb_df[188]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size= 0.2, random_state = 321)\n",
    "\n",
    "# since our data is not normal distributed I decided not to use Standard-Scaler here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         -1       0.78      0.31      0.78      0.45      0.49      0.23      2101\n",
      "          1       0.30      0.78      0.31      0.44      0.49      0.25       809\n",
      "\n",
      "avg / total       0.65      0.44      0.65      0.44      0.49      0.24      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "isof = IsolationForest(contamination = 0.278, n_estimators = 100, n_jobs=-1)\n",
    "\n",
    "isof.fit(X_train)\n",
    "y_pred = isof.predict(X_test)\n",
    "pd.crosstab(y_test, y_pred)\n",
    "print (\"\\n\")\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With SC: prec 0.81, rec 0.32\n",
    "- Without SC: prec 0.81, rec 0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Hyperparameter: {'contamination': np.float64(0.1), 'n_estimators': 300} \n",
      "\n",
      "\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         -1       0.84      0.11      0.95      0.20      0.32      0.10      2101\n",
      "          1       0.29      0.95      0.11      0.44      0.32      0.11       809\n",
      "\n",
      "avg / total       0.69      0.34      0.71      0.26      0.32      0.10      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recall Optimization with Cross-Validation and Hyperparameter Optimization\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3) \n",
    "folds = list(skf.split(X_train, y_train))\n",
    "forest = IsolationForest()\n",
    "\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "resc = make_scorer(recall_score,pos_label=-1)\n",
    "\n",
    "params = {'contamination': np.linspace(0.001, 0.1, 10), 'n_estimators': [100,200,300]}\n",
    "\n",
    "search = GridSearchCV(estimator=forest, param_grid=params, scoring=resc, cv=folds, n_jobs=-1)\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "best_params = search.best_params_\n",
    "print(\"Beste Hyperparameter:\", best_params, \"\\n\")\n",
    "\n",
    "# predict\n",
    "optimal_forest = search.best_estimator_\n",
    "y_pred = optimal_forest.predict(X_test)\n",
    "\n",
    "pd.crosstab(y_test, y_pred, rownames=['Reality'], colnames=['Prediction'])\n",
    "print(\"\\n\", classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With SC: prec 0.80, rec 0.44\n",
    "- Without SC: 0.78, rec 0.44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **One Class SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: \n",
    "\n",
    "# We select only the labels that correspond to 1\n",
    "y_inliers = y_train[y_train.values==1]\n",
    "\n",
    "# We create a list of indexes to be able to recover the explanatory variables of these indexes\n",
    "liste = list(y_inliers.index.values)\n",
    "\n",
    "# We recover these explanatory variables in a new DataFrame\n",
    "X_train_inliers = X_train.loc[liste]\n",
    "y_train_inliers = y_train.loc[liste]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (-1,1))\n",
    "\n",
    "X_train_inliers = scaler.fit_transform(X_train_inliers)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.34      0.49      2101\n",
      "           1       0.33      0.85      0.48       809\n",
      "\n",
      "    accuracy                           0.48      2910\n",
      "   macro avg       0.60      0.60      0.48      2910\n",
      "weighted avg       0.71      0.48      0.49      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "ocsvm = OneClassSVM(nu=0.278, kernel = \"rbf\", gamma = \"scale\")\n",
    "\n",
    "ocsvm.fit(X_train_inliers)\n",
    "\n",
    "y_pred = ocsvm.predict(X_test)\n",
    "\n",
    "pd.crosstab(y_test, y_pred, rownames = [\"Reality\"], colnames = [\"Prediction\"])\n",
    "print(\"\\n\", classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With SC: prec 0.86, rec 0.34\n",
    "- Without SC: 0.88, rec 0.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Hyperparameter: {'gamma': 'scale', 'kernel': 'rbf', 'nu': np.float64(0.01)}\n",
      "Prediction  -1     1\n",
      "Reality             \n",
      "-1          68  2033\n",
      " 1           4   805\n",
      "\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "         -1       0.94      0.03      1.00      0.06      0.18      0.03      2101\n",
      "          1       0.28      1.00      0.03      0.44      0.18      0.04       809\n",
      "\n",
      "avg / total       0.76      0.30      0.73      0.17      0.18      0.03      2910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# One Class SVM Grid Search\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# StratifiedKFold for cross-validation\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "folds = list(skf.split(X_train_inliers, y_train_inliers))\n",
    "\n",
    "# Custom scorer for recall\n",
    "resc = make_scorer(recall_score, pos_label=-1)\n",
    "\n",
    "# Parameter grid for hyperparameter optimization with different kernels\n",
    "params = {\n",
    "    'kernel': ['rbf'],\n",
    "    'nu': np.linspace(0.01, 0.3, 10),  # Parameter for One-Class SVM\n",
    "    'gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
    "}\n",
    "\n",
    "# One-Class SVM\n",
    "ocsvm = OneClassSVM()\n",
    "\n",
    "# GridSearchCV for hyperparameter optimization\n",
    "search = GridSearchCV(estimator=ocsvm, param_grid=params, scoring=resc, cv=folds, n_jobs=-1)\n",
    "search.fit(X_train_inliers, y_train_inliers)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = search.best_params_\n",
    "print(\"Beste Hyperparameter:\", best_params)\n",
    "\n",
    "# Best estimator\n",
    "optimal_ocsvm = search.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred = optimal_ocsvm.predict(X_test)\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "print(pd.crosstab(y_test, y_pred, rownames=['Reality'], colnames=['Prediction']))\n",
    "print(\"\\n\", classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With SC: prec 0.94, rec 0.03\n",
    "- Without SC: 0.98, rec 0.42"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
